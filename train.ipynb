{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import os\n",
    "from models import EncoderRNN, LuongAttnDecoderRNN\n",
    "from vocabulary import Voc\n",
    "import itertools\n",
    "import random\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "\n",
    "voc = Voc(\"FriendsCorpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPreparedData(preprocessed_file):\n",
    "    pairs = []\n",
    "    with open(preprocessed_file, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) == 2:\n",
    "                pairs.append(parts)\n",
    "            else:\n",
    "                print(f\"Skipping malformed line: {line.strip()}\")\n",
    "    return pairs\n",
    "\n",
    "def addPairsToVoc(voc, pairs):\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping malformed line: me neither .\n",
      "Skipping malformed line: joey you don't have to count down every time we kiss .\n",
      "Skipping malformed line: i can do it okay ? come on let's go .\n",
      "Skipping malformed line: i can't do it !\n"
     ]
    }
   ],
   "source": [
    "pairs = loadPreparedData(\"preprocessed_pairs.txt\")\n",
    "addPairsToVoc(voc, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55486, 16041)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs), voc.num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimRareWords(voc, pairs, min_count=3):\n",
    "    # Trim words used under the MIN_COUNT from the voc\n",
    "    voc.trim(min_count)\n",
    "    # Filter out pairs with trimmed words\n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "        # Check input sentence\n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input = False\n",
    "                break\n",
    "        # Check output sentence\n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "\n",
    "        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "\n",
    "    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
    "    return keep_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 8898 / 16038 = 0.5548\n",
      "Trimmed from 55486 pairs to 45901, 0.8273 of total\n"
     ]
    }
   ],
   "source": [
    "pairs = trimRareWords(voc, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45901, 8901)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs), voc.num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters and hyperparameters\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 64\n",
    "clip = 50.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 4000\n",
    "print_every = n_iteration // 100\n",
    "save_every = 500\n",
    "teacher_forcing_ratio = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimizers...\n"
     ]
    }
   ],
   "source": [
    "# Choose device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize models\n",
    "encoder = EncoderRNN(hidden_size=hidden_size, \n",
    "                     embedding=nn.Embedding(num_embeddings=voc.num_words, embedding_dim=hidden_size),\n",
    "                     n_layers=encoder_n_layers, \n",
    "                     dropout=dropout).to(device)\n",
    "\n",
    "decoder = LuongAttnDecoderRNN(attn_model='dot', \n",
    "                              embedding=nn.Embedding(num_embeddings=voc.num_words, embedding_dim=hidden_size), \n",
    "                              hidden_size=hidden_size, \n",
    "                              output_size=voc.num_words, \n",
    "                              n_layers=decoder_n_layers, \n",
    "                              dropout=dropout).to(device)\n",
    "\n",
    "# Initialize optimizers\n",
    "print('Building optimizers...')\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index.get(word) for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "def zeroPadding(l, fillvalue=0):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
    "\n",
    "def binaryMatrix(l, value=0):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == value:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "\n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.BoolTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len\n",
    "\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskNLLLoss(inp, target, mask):\n",
    "    nTotal = mask.sum()\n",
    "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = crossEntropy.masked_select(mask).mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, encoder_optimizer, decoder_optimizer, batch_size, clip, max_length, teacher_forcing_ratio):\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_variable = input_variable.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths, None)\n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden, _ = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_input = target_variable[t].view(1, -1)\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden, _ = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            _, topi = decoder_output.topk(1)\n",
    "\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return sum(print_losses), n_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 40; Percent complete: 1.0%; Average loss: 6.6350\n",
      "Iteration: 80; Percent complete: 2.0%; Average loss: 5.7125\n",
      "Iteration: 120; Percent complete: 3.0%; Average loss: 5.6347\n",
      "Iteration: 160; Percent complete: 4.0%; Average loss: 5.5997\n",
      "Iteration: 200; Percent complete: 5.0%; Average loss: 5.4916\n",
      "Iteration: 240; Percent complete: 6.0%; Average loss: 5.4354\n",
      "Iteration: 280; Percent complete: 7.0%; Average loss: 5.4344\n",
      "Iteration: 320; Percent complete: 8.0%; Average loss: 5.3948\n",
      "Iteration: 360; Percent complete: 9.0%; Average loss: 5.2953\n",
      "Iteration: 400; Percent complete: 10.0%; Average loss: 5.3268\n",
      "Iteration: 440; Percent complete: 11.0%; Average loss: 5.2158\n",
      "Iteration: 480; Percent complete: 12.0%; Average loss: 5.2519\n",
      "Iteration: 520; Percent complete: 13.0%; Average loss: 5.2048\n",
      "Iteration: 560; Percent complete: 14.0%; Average loss: 5.2508\n",
      "Iteration: 600; Percent complete: 15.0%; Average loss: 5.2567\n",
      "Iteration: 640; Percent complete: 16.0%; Average loss: 5.0851\n",
      "Iteration: 680; Percent complete: 17.0%; Average loss: 5.0985\n",
      "Iteration: 720; Percent complete: 18.0%; Average loss: 5.1684\n",
      "Iteration: 760; Percent complete: 19.0%; Average loss: 5.1247\n",
      "Iteration: 800; Percent complete: 20.0%; Average loss: 5.0253\n",
      "Iteration: 840; Percent complete: 21.0%; Average loss: 5.1638\n",
      "Iteration: 880; Percent complete: 22.0%; Average loss: 5.0343\n",
      "Iteration: 920; Percent complete: 23.0%; Average loss: 5.0808\n",
      "Iteration: 960; Percent complete: 24.0%; Average loss: 5.0002\n",
      "Iteration: 1000; Percent complete: 25.0%; Average loss: 5.0592\n",
      "Iteration: 1040; Percent complete: 26.0%; Average loss: 5.0660\n",
      "Iteration: 1080; Percent complete: 27.0%; Average loss: 4.9438\n",
      "Iteration: 1120; Percent complete: 28.0%; Average loss: 4.9959\n",
      "Iteration: 1160; Percent complete: 29.0%; Average loss: 5.0901\n",
      "Iteration: 1200; Percent complete: 30.0%; Average loss: 4.9059\n",
      "Iteration: 1240; Percent complete: 31.0%; Average loss: 5.0601\n",
      "Iteration: 1280; Percent complete: 32.0%; Average loss: 5.1255\n",
      "Iteration: 1320; Percent complete: 33.0%; Average loss: 4.9061\n",
      "Iteration: 1360; Percent complete: 34.0%; Average loss: 4.9725\n",
      "Iteration: 1400; Percent complete: 35.0%; Average loss: 4.9274\n",
      "Iteration: 1440; Percent complete: 36.0%; Average loss: 4.9039\n",
      "Iteration: 1480; Percent complete: 37.0%; Average loss: 4.9375\n",
      "Iteration: 1520; Percent complete: 38.0%; Average loss: 4.9547\n",
      "Iteration: 1560; Percent complete: 39.0%; Average loss: 4.9139\n",
      "Iteration: 1600; Percent complete: 40.0%; Average loss: 4.9409\n",
      "Iteration: 1640; Percent complete: 41.0%; Average loss: 4.9666\n",
      "Iteration: 1680; Percent complete: 42.0%; Average loss: 4.8959\n",
      "Iteration: 1720; Percent complete: 43.0%; Average loss: 5.1491\n",
      "Iteration: 1760; Percent complete: 44.0%; Average loss: 4.9575\n",
      "Iteration: 1800; Percent complete: 45.0%; Average loss: 4.9201\n",
      "Iteration: 1840; Percent complete: 46.0%; Average loss: 4.9202\n",
      "Iteration: 1880; Percent complete: 47.0%; Average loss: 4.9219\n",
      "Iteration: 1920; Percent complete: 48.0%; Average loss: 4.7998\n",
      "Iteration: 1960; Percent complete: 49.0%; Average loss: 4.8723\n",
      "Iteration: 2000; Percent complete: 50.0%; Average loss: 4.9026\n",
      "Iteration: 2040; Percent complete: 51.0%; Average loss: 5.0451\n",
      "Iteration: 2080; Percent complete: 52.0%; Average loss: 4.8391\n",
      "Iteration: 2120; Percent complete: 53.0%; Average loss: 4.7900\n",
      "Iteration: 2160; Percent complete: 54.0%; Average loss: 4.7950\n",
      "Iteration: 2200; Percent complete: 55.0%; Average loss: 4.8886\n",
      "Iteration: 2240; Percent complete: 56.0%; Average loss: 4.8967\n",
      "Iteration: 2280; Percent complete: 57.0%; Average loss: 4.7992\n",
      "Iteration: 2320; Percent complete: 58.0%; Average loss: 4.9781\n",
      "Iteration: 2360; Percent complete: 59.0%; Average loss: 4.7082\n",
      "Iteration: 2400; Percent complete: 60.0%; Average loss: 4.7995\n",
      "Iteration: 2440; Percent complete: 61.0%; Average loss: 4.6555\n",
      "Iteration: 2480; Percent complete: 62.0%; Average loss: 4.8812\n",
      "Iteration: 2520; Percent complete: 63.0%; Average loss: 4.7454\n",
      "Iteration: 2560; Percent complete: 64.0%; Average loss: 4.8439\n",
      "Iteration: 2600; Percent complete: 65.0%; Average loss: 4.7646\n",
      "Iteration: 2640; Percent complete: 66.0%; Average loss: 4.8631\n",
      "Iteration: 2680; Percent complete: 67.0%; Average loss: 4.9383\n",
      "Iteration: 2720; Percent complete: 68.0%; Average loss: 4.7984\n",
      "Iteration: 2760; Percent complete: 69.0%; Average loss: 4.7319\n",
      "Iteration: 2800; Percent complete: 70.0%; Average loss: 4.5974\n",
      "Iteration: 2840; Percent complete: 71.0%; Average loss: 4.7622\n",
      "Iteration: 2880; Percent complete: 72.0%; Average loss: 4.7286\n",
      "Iteration: 2920; Percent complete: 73.0%; Average loss: 4.7918\n",
      "Iteration: 2960; Percent complete: 74.0%; Average loss: 4.8361\n",
      "Iteration: 3000; Percent complete: 75.0%; Average loss: 4.8179\n",
      "Iteration: 3040; Percent complete: 76.0%; Average loss: 4.6348\n",
      "Iteration: 3080; Percent complete: 77.0%; Average loss: 4.6787\n",
      "Iteration: 3120; Percent complete: 78.0%; Average loss: 4.8869\n",
      "Iteration: 3160; Percent complete: 79.0%; Average loss: 4.6776\n",
      "Iteration: 3200; Percent complete: 80.0%; Average loss: 4.7961\n",
      "Iteration: 3240; Percent complete: 81.0%; Average loss: 4.7181\n",
      "Iteration: 3280; Percent complete: 82.0%; Average loss: 4.6560\n",
      "Iteration: 3320; Percent complete: 83.0%; Average loss: 4.8421\n",
      "Iteration: 3360; Percent complete: 84.0%; Average loss: 4.6873\n",
      "Iteration: 3400; Percent complete: 85.0%; Average loss: 4.8152\n",
      "Iteration: 3440; Percent complete: 86.0%; Average loss: 4.6941\n",
      "Iteration: 3480; Percent complete: 87.0%; Average loss: 4.8394\n",
      "Iteration: 3520; Percent complete: 88.0%; Average loss: 4.9000\n",
      "Iteration: 3560; Percent complete: 89.0%; Average loss: 4.6692\n",
      "Iteration: 3600; Percent complete: 90.0%; Average loss: 4.8445\n",
      "Iteration: 3640; Percent complete: 91.0%; Average loss: 4.8404\n",
      "Iteration: 3680; Percent complete: 92.0%; Average loss: 4.9406\n",
      "Iteration: 3720; Percent complete: 93.0%; Average loss: 4.6375\n",
      "Iteration: 3760; Percent complete: 94.0%; Average loss: 4.7090\n",
      "Iteration: 3800; Percent complete: 95.0%; Average loss: 4.5180\n",
      "Iteration: 3840; Percent complete: 96.0%; Average loss: 4.8004\n",
      "Iteration: 3880; Percent complete: 97.0%; Average loss: 4.7676\n",
      "Iteration: 3920; Percent complete: 98.0%; Average loss: 4.8214\n",
      "Iteration: 3960; Percent complete: 99.0%; Average loss: 4.7261\n",
      "Iteration: 4000; Percent complete: 100.0%; Average loss: 4.6723\n"
     ]
    }
   ],
   "source": [
    "# Initialize print_loss for tracking progress\n",
    "print_loss = 0\n",
    "print_total_words = 0\n",
    "losses = []\n",
    "total_words = []\n",
    "\n",
    "for iteration in range(1, n_iteration + 1):\n",
    "    training_batch = [random.choice(pairs) for _ in range(batch_size)]\n",
    "    # Extract fields from batch\n",
    "    input_variable, lengths, target_variable, mask, max_target_len = batch2TrainData(voc, training_batch)\n",
    "    \n",
    "    # Run a training iteration\n",
    "    loss, n_total = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
    "                 decoder, encoder_optimizer, decoder_optimizer, batch_size, clip, device, teacher_forcing_ratio)\n",
    "    \n",
    "    print_loss += loss\n",
    "    print_total_words += n_total\n",
    "    losses.append(loss)\n",
    "    total_words.append(n_total)\n",
    "    \n",
    "    # Print progress\n",
    "    if iteration % print_every == 0:\n",
    "        print_loss_avg = print_loss / print_every\n",
    "        print(f\"Iteration: {iteration}; Percent complete: {iteration / n_iteration * 100:.1f}%; Average loss: {print_loss_avg:.4f}\")\n",
    "        print_loss = 0\n",
    "        print_total_words = 0\n",
    "\n",
    "    # Save checkpoint\n",
    "    if iteration % save_every == 0:\n",
    "        directory = os.path.join(\"checkpoints\")\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        torch.save({\n",
    "            'iteration': iteration,\n",
    "            'en': encoder.state_dict(),\n",
    "            'de': decoder.state_dict(),\n",
    "            'en_opt': encoder_optimizer.state_dict(),\n",
    "            'de_opt': decoder_optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            'voc_dict': voc.__dict__,\n",
    "        }, os.path.join(directory, f'{iteration}_checkpoint.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=10):\n",
    "    ### Format input sentence as a batch\n",
    "    # words -> indexes\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
    "    # Create lengths tensor\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # Transpose dimensions of batch to match models' expectations\n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    # Use appropriate device\n",
    "    input_batch = input_batch.to(device)\n",
    "    lengths = lengths.to(\"cpu\")\n",
    "    \n",
    "    # Decode sentence with searcher\n",
    "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words\n",
    "\n",
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        # Forward input through encoder model\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        # Initialize decoder input with SOS_token\n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        # Initialize tensors to append decoded words to\n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "        # Iteratively decode one word token at a time\n",
    "        for _ in range(max_length):\n",
    "            decoder_output, decoder_hidden, _ = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Obtain most likely word token and its softmax score\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            # Prepare current token to be next decoder input (add a dimension)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        # Return collections of word tokens and scores\n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: how are you ?\n",
      "Output: yeah i i EOS i EOS i EOS i EOS\n"
     ]
    }
   ],
   "source": [
    "# Example call to evaluate function\n",
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "\n",
    "# Input sentence\n",
    "input_sentence = \"how are you ?\"\n",
    "\n",
    "# Evaluate sentence\n",
    "output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "output_sentence = ' '.join(output_words)\n",
    "\n",
    "print('Input:', input_sentence)\n",
    "print('Output:', output_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: how are you ?\n",
    "Output: yeah i was the one i was in the bathroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, voc, sentence, max_length=5, beam_width=5):\n",
    "    with torch.no_grad():\n",
    "        # Convert input sentence to indexes and add EOS token\n",
    "        indexes_batch = [indexesFromSentence(voc, sentence)]\n",
    "        lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "        input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "\n",
    "        # Forward input through encoder model\n",
    "        encoder_outputs, encoder_hidden = encoder(input_batch, lengths, None)\n",
    "\n",
    "        # Create starting vectors for decoder\n",
    "        decoder_input = torch.LongTensor([[SOS_token]])  # SOS\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "\n",
    "        # Initialize the Beam search\n",
    "        topk = 2  # how many sentences to generate\n",
    "        decoded_batch = []\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        for _ in range(topk):\n",
    "            # Start with the first word (SOS_token)\n",
    "            decoder_input = torch.LongTensor([[SOS_token]])  # SOS\n",
    "\n",
    "            # Number of steps to unroll\n",
    "            for i in range(max_length):\n",
    "                # Forward pass through decoder\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs\n",
    "                )\n",
    "\n",
    "                # Obtain word with highest probability and its index\n",
    "                prob, index = torch.topk(decoder_output, beam_width)\n",
    "                print(f'step {i}: prob {prob}, index {index}')\n",
    "                prob = prob.detach().cpu().numpy().tolist()[0]\n",
    "                index = index.detach().cpu().numpy().tolist()[0]\n",
    "\n",
    "                # Create new set of input\n",
    "                decoder_input = torch.LongTensor([[index[0]]])\n",
    "\n",
    "                # Break if EOS token generated\n",
    "                if index[0] == EOS_token:\n",
    "                    break\n",
    "\n",
    "            # Add the decoded sentence to the list\n",
    "            decoded_batch.append(index)\n",
    "    return decoded_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: prob tensor([[0.1478, 0.0719, 0.0684, 0.0465, 0.0366]]), index tensor([[50, 47, 51, 12, 82]])\n",
      "step 1: prob tensor([[0.2157, 0.0966, 0.0458, 0.0437, 0.0408]]), index tensor([[  7,  29,  55, 105,  36]])\n",
      "step 2: prob tensor([[0.1963, 0.0717, 0.0576, 0.0390, 0.0369]]), index tensor([[  7,  29,   2, 105,  55]])\n",
      "step 3: prob tensor([[0.1860, 0.0801, 0.0687, 0.0424, 0.0341]]), index tensor([[ 7,  2, 29, 55, 36]])\n",
      "step 4: prob tensor([[0.1793, 0.0799, 0.0635, 0.0493, 0.0465]]), index tensor([[ 7,  2, 29, 55, 36]])\n",
      "step 0: prob tensor([[0.2765, 0.0929, 0.0601, 0.0464, 0.0250]]), index tensor([[ 7, 29, 36, 55,  2]])\n",
      "step 1: prob tensor([[0.1945, 0.0927, 0.0674, 0.0388, 0.0339]]), index tensor([[ 7,  2, 29, 55, 36]])\n",
      "step 2: prob tensor([[0.1714, 0.1012, 0.0654, 0.0446, 0.0353]]), index tensor([[ 7,  2, 29, 55, 36]])\n",
      "step 3: prob tensor([[0.1543, 0.1026, 0.0611, 0.0496, 0.0402]]), index tensor([[ 7,  2, 29, 55, 36]])\n",
      "step 4: prob tensor([[0.1514, 0.1073, 0.0600, 0.0488, 0.0403]]), index tensor([[ 7,  2, 29, 55, 36]])\n",
      "Input: there's nothing to tell ! he's just some guy i work with !\n",
      "Output 0: ! EOS . is ?\n",
      "Output 1: ! EOS . is ?\n"
     ]
    }
   ],
   "source": [
    "sentence = \"there's nothing to tell ! he's just some guy i work with !\"\n",
    "output_words = evaluate(encoder, decoder, voc, sentence)\n",
    "print('Input:', sentence)\n",
    "for idx in range(len(output_words)):\n",
    "    print(f'Output {idx}:', ' '.join([voc.index2word[token] for token in output_words[idx]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc.index2word[29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
