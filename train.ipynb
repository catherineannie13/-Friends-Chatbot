{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from models import EncoderRNN, LuongAttnDecoderRNN\n",
    "from vocabulary import Voc\n",
    "import itertools\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "from utils import loadPreparedData, split_data, addPairsToVoc, trimRareWords, indexesFromSentence, zeroPadding, binaryMatrix, inputVar, outputVar, batch2TrainData, maskNLLLoss, train, validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data, Trimming Words & Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping malformed line: me neither .\n",
      "Skipping malformed line: joey you don't have to count down every time we kiss .\n",
      "Skipping malformed line: i can do it okay ? come on let's go .\n",
      "Skipping malformed line: i can't do it !\n",
      "Training pairs: 49937\n",
      "Validation pairs: 5549\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed pairs\n",
    "pairs = loadPreparedData(\"preprocessed_pairs.txt\")\n",
    "\n",
    "# Split data into training and validation sets\n",
    "training_pairs, validation_pairs = split_data(pairs, 0.9)\n",
    "\n",
    "print(f\"Training pairs: {len(training_pairs)}\")\n",
    "print(f\"Validation pairs: {len(validation_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 6110 / 15826 = 0.3861\n",
      "Trimmed from 49937 pairs to 36300, 0.7269 of total\n",
      "Training pairs: 36300\n",
      "Validation pairs: 3859\n"
     ]
    }
   ],
   "source": [
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "\n",
    "# Create vocabulary and add pairs to it\n",
    "voc = Voc(\"FriendsCorpus\", \n",
    "          PAD_token=PAD_token, \n",
    "          SOS_token=SOS_token, \n",
    "          EOS_token=EOS_token)\n",
    "addPairsToVoc(voc, training_pairs)\n",
    "\n",
    "# Trim rare words\n",
    "training_pairs = trimRareWords(voc, training_pairs)\n",
    "\n",
    "# Remove validation pairs that contain words not in the vocabulary\n",
    "validation_pairs = [pair for pair in validation_pairs if all(word in voc.word2index for word in pair[0].split()) and all(word in voc.word2index for word in pair[1].split())]\n",
    "\n",
    "print(f\"Training pairs: {len(training_pairs)}\")\n",
    "print(f\"Validation pairs: {len(validation_pairs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters and hyperparameters\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 64\n",
    "clip = 50.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 4000\n",
    "print_every = n_iteration // 100\n",
    "save_every = 500\n",
    "validate_every = n_iteration // 100\n",
    "teacher_forcing_ratio = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimizers...\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "encoder = EncoderRNN(hidden_size=hidden_size, \n",
    "                     embedding=nn.Embedding(num_embeddings=voc.num_words, embedding_dim=hidden_size),\n",
    "                     n_layers=encoder_n_layers, \n",
    "                     dropout=dropout)\n",
    "\n",
    "decoder = LuongAttnDecoderRNN(attn_model='dot', \n",
    "                              embedding=nn.Embedding(num_embeddings=voc.num_words, embedding_dim=hidden_size), \n",
    "                              hidden_size=hidden_size, \n",
    "                              output_size=voc.num_words, \n",
    "                              n_layers=decoder_n_layers, \n",
    "                              dropout=dropout)\n",
    "\n",
    "# Initialize optimizers\n",
    "print('Building optimizers...')\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Iteration: 40; Average loss: 5.6308\n",
      "Training - Iteration: 40; Average loss: 4541.1929; Perplexity: 514.42\n",
      "Validation - Iteration: 80; Average loss: 5.6236\n",
      "Training - Iteration: 80; Average loss: 4160.2117; Perplexity: 268.84\n",
      "Validation - Iteration: 120; Average loss: 5.5883\n",
      "Training - Iteration: 120; Average loss: 4131.7711; Perplexity: 250.30\n",
      "Validation - Iteration: 160; Average loss: 5.5457\n",
      "Training - Iteration: 160; Average loss: 3972.9066; Perplexity: 229.48\n",
      "Validation - Iteration: 200; Average loss: 5.5174\n",
      "Training - Iteration: 200; Average loss: 3798.7093; Perplexity: 216.04\n",
      "Validation - Iteration: 240; Average loss: 5.4962\n",
      "Training - Iteration: 240; Average loss: 3715.9675; Perplexity: 194.55\n",
      "Validation - Iteration: 280; Average loss: 5.5593\n",
      "Training - Iteration: 280; Average loss: 3758.5097; Perplexity: 192.72\n",
      "Validation - Iteration: 320; Average loss: 5.4644\n",
      "Training - Iteration: 320; Average loss: 3713.6651; Perplexity: 184.26\n",
      "Validation - Iteration: 360; Average loss: 5.4387\n",
      "Training - Iteration: 360; Average loss: 3733.3382; Perplexity: 173.26\n",
      "Validation - Iteration: 400; Average loss: 5.4360\n",
      "Training - Iteration: 400; Average loss: 3800.3833; Perplexity: 186.59\n",
      "Validation - Iteration: 440; Average loss: 5.4264\n",
      "Training - Iteration: 440; Average loss: 3716.7381; Perplexity: 169.66\n",
      "Validation - Iteration: 480; Average loss: 5.4526\n",
      "Training - Iteration: 480; Average loss: 3642.0531; Perplexity: 152.08\n",
      "Validation - Iteration: 520; Average loss: 5.6372\n",
      "Training - Iteration: 520; Average loss: 3708.5151; Perplexity: 150.74\n",
      "Validation - Iteration: 560; Average loss: 5.4227\n",
      "Training - Iteration: 560; Average loss: 3797.2445; Perplexity: 170.52\n",
      "Validation - Iteration: 600; Average loss: 5.4401\n",
      "Training - Iteration: 600; Average loss: 3690.1828; Perplexity: 153.63\n",
      "Validation - Iteration: 640; Average loss: 5.4216\n",
      "Training - Iteration: 640; Average loss: 3771.0841; Perplexity: 169.05\n",
      "Validation - Iteration: 680; Average loss: 5.4288\n",
      "Training - Iteration: 680; Average loss: 3534.2311; Perplexity: 147.57\n",
      "Validation - Iteration: 720; Average loss: 5.3943\n",
      "Training - Iteration: 720; Average loss: 3608.4468; Perplexity: 145.96\n",
      "Validation - Iteration: 760; Average loss: 5.4162\n",
      "Training - Iteration: 760; Average loss: 3621.2399; Perplexity: 148.39\n",
      "Validation - Iteration: 800; Average loss: 5.4389\n",
      "Training - Iteration: 800; Average loss: 3680.8443; Perplexity: 149.55\n",
      "Validation - Iteration: 840; Average loss: 5.3982\n",
      "Training - Iteration: 840; Average loss: 3708.8652; Perplexity: 134.30\n",
      "Validation - Iteration: 880; Average loss: 5.4031\n",
      "Training - Iteration: 880; Average loss: 3830.9370; Perplexity: 174.35\n",
      "Validation - Iteration: 920; Average loss: 5.4143\n",
      "Training - Iteration: 920; Average loss: 3628.8765; Perplexity: 143.40\n",
      "Validation - Iteration: 960; Average loss: 5.3988\n",
      "Training - Iteration: 960; Average loss: 3597.2716; Perplexity: 156.00\n",
      "Validation - Iteration: 1000; Average loss: 5.4121\n",
      "Training - Iteration: 1000; Average loss: 3595.0130; Perplexity: 145.74\n",
      "Validation - Iteration: 1040; Average loss: 5.3985\n",
      "Training - Iteration: 1040; Average loss: 3704.7089; Perplexity: 149.08\n",
      "Validation - Iteration: 1080; Average loss: 5.4006\n",
      "Training - Iteration: 1080; Average loss: 3660.7227; Perplexity: 153.92\n",
      "Validation - Iteration: 1120; Average loss: 5.4036\n",
      "Training - Iteration: 1120; Average loss: 3575.8079; Perplexity: 129.57\n",
      "Validation - Iteration: 1160; Average loss: 5.4957\n",
      "Training - Iteration: 1160; Average loss: 3539.8209; Perplexity: 114.41\n",
      "Validation - Iteration: 1200; Average loss: 5.3931\n",
      "Training - Iteration: 1200; Average loss: 3606.2613; Perplexity: 136.55\n",
      "Validation - Iteration: 1240; Average loss: 5.3989\n",
      "Training - Iteration: 1240; Average loss: 3452.3724; Perplexity: 119.80\n",
      "Validation - Iteration: 1280; Average loss: 5.4054\n",
      "Training - Iteration: 1280; Average loss: 3665.1752; Perplexity: 135.44\n",
      "Validation - Iteration: 1320; Average loss: 5.4110\n",
      "Training - Iteration: 1320; Average loss: 3526.7658; Perplexity: 129.65\n",
      "Validation - Iteration: 1360; Average loss: 5.3949\n",
      "Training - Iteration: 1360; Average loss: 3584.1948; Perplexity: 133.61\n",
      "Validation - Iteration: 1400; Average loss: 5.3960\n",
      "Training - Iteration: 1400; Average loss: 3741.7479; Perplexity: 146.08\n",
      "Validation - Iteration: 1440; Average loss: 5.3897\n",
      "Training - Iteration: 1440; Average loss: 3458.7728; Perplexity: 128.46\n",
      "Validation - Iteration: 1480; Average loss: 5.4120\n",
      "Training - Iteration: 1480; Average loss: 3446.6804; Perplexity: 115.54\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m input_variable, lengths, target_variable, mask, max_target_len \u001b[38;5;241m=\u001b[39m batch2TrainData(voc, training_batch)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Run a training iteration\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m loss, n_total \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_variable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_variable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_target_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m             \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m print_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m     21\u001b[0m print_total_words \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m n_total\n",
      "File \u001b[1;32mc:\\Users\\cathe\\custom_chatbot\\utils_train.py:153\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, encoder_optimizer, decoder_optimizer, batch_size, clip, teacher_forcing_ratio)\u001b[0m\n\u001b[0;32m    150\u001b[0m         print_losses\u001b[38;5;241m.\u001b[39mappend(mask_loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m nTotal)\n\u001b[0;32m    151\u001b[0m         n_totals \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m nTotal\n\u001b[1;32m--> 153\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m _ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(encoder\u001b[38;5;241m.\u001b[39mparameters(), clip)\n\u001b[0;32m    156\u001b[0m _ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(decoder\u001b[38;5;241m.\u001b[39mparameters(), clip)\n",
      "File \u001b[1;32mc:\\Users\\cathe\\custom_chatbot\\venv\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cathe\\custom_chatbot\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize print_loss for tracking progress\n",
    "print_loss = 0\n",
    "print_total_words = 0\n",
    "losses = []\n",
    "total_words = []\n",
    "loss_avgs = []\n",
    "perplexity_scores = []\n",
    "loss_avgs_val = []\n",
    "perplexity_scores_val = []\n",
    "\n",
    "for iteration in range(1, n_iteration + 1):\n",
    "    training_batch = [random.choice(training_pairs) for _ in range(batch_size)]\n",
    "    # Extract fields from batch\n",
    "    input_variable, lengths, target_variable, mask, max_target_len = batch2TrainData(voc, training_batch)\n",
    "    \n",
    "    # Run a training iteration\n",
    "    loss, n_total = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
    "                 decoder, encoder_optimizer, decoder_optimizer, batch_size, clip, teacher_forcing_ratio)\n",
    "    \n",
    "    print_loss += loss\n",
    "    print_total_words += n_total\n",
    "    losses.append(loss)\n",
    "    total_words.append(n_total)\n",
    "\n",
    "    # Validation \n",
    "    if iteration % validate_every == 0:\n",
    "        validation_batches = [validation_pairs[i:i+batch_size] for i in range(0, len(validation_pairs), batch_size)][:-1]\n",
    "        n_validation = len(validation_batches)\n",
    "        validation_loss = 0\n",
    "\n",
    "        for i in range(n_validation):\n",
    "            validation_batch = validation_batches[i]\n",
    "            input_variable, lengths, target_variable, mask, max_target_len = batch2TrainData(voc, validation_batch)\n",
    "            validation_loss += validate(encoder, decoder, batch_size, input_variable, lengths, target_variable, mask, max_target_len)\n",
    "\n",
    "        validation_loss_avg = validation_loss / n_validation\n",
    "        perplexity_val = torch.exp(torch.tensor(validation_loss / len(validation_pairs)))\n",
    "        loss_avgs_val.append(validation_loss_avg)\n",
    "        perplexity_scores_val.append(perplexity_val)\n",
    "\n",
    "    # Print progress\n",
    "    if iteration % print_every == 0:\n",
    "        print_loss_avg = print_loss / print_every\n",
    "        perplexity = torch.exp(torch.tensor(print_loss / print_total_words))\n",
    "        loss_avgs.append(print_loss_avg)\n",
    "        perplexity_scores.append(perplexity)\n",
    "        print(f\"Training - Iteration: {iteration}; Average loss: {print_loss_avg:.4f}\")\n",
    "        print_loss = 0\n",
    "        print_total_words = 0\n",
    "\n",
    "    # Save checkpoint\n",
    "    if iteration % save_every == 0:\n",
    "        directory = os.path.join(\"checkpoints\")\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        torch.save({\n",
    "            'iteration': iteration,\n",
    "            'en': encoder.state_dict(),\n",
    "            'de': decoder.state_dict(),\n",
    "            'en_opt': encoder_optimizer.state_dict(),\n",
    "            'de_opt': decoder_optimizer.state_dict(),\n",
    "            'train loss': loss_avgs,\n",
    "            'val loss': loss_avgs_val,\n",
    "            'train perplexity': perplexity_scores,\n",
    "            'val perplexity': perplexity_scores_val,\n",
    "            'voc_dict': voc.__dict__,\n",
    "        }, os.path.join(directory, f'{iteration}_checkpoint.tar'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
