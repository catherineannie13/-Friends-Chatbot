{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from models import EncoderRNN, LuongAttnDecoderRNN, GreedySearchDecoder, BeamSearchDecoder\n",
    "from vocabulary import Voc\n",
    "from utils import evaluate, normalizeString, calculate_distinct_n_grams\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the checkpoint file\n",
    "checkpoint_path = 'checkpoints/4000_checkpoint.tar'\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# Access the information from the checkpoint\n",
    "iteration = checkpoint['iteration']\n",
    "encoder_state_dict = checkpoint['en']\n",
    "decoder_state_dict = checkpoint['de']\n",
    "encoder_optimizer_state_dict = checkpoint['en_opt']\n",
    "decoder_optimizer_state_dict = checkpoint['de_opt']\n",
    "train_loss = checkpoint['train loss']\n",
    "val_loss = checkpoint['val loss']\n",
    "train_perplexity = checkpoint['train perplexity']\n",
    "val_perplexity = checkpoint['val perplexity']\n",
    "voc_dict = checkpoint['voc_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct vocabulary\n",
    "voc = Voc(voc_dict['name'])\n",
    "voc.__dict__ = voc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LuongAttnDecoderRNN(\n",
       "  (embedding): Embedding(8901, 500)\n",
       "  (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (gru): GRU(500, 500, num_layers=2, dropout=0.1)\n",
       "  (concat): Linear(in_features=1000, out_features=500, bias=True)\n",
       "  (out): Linear(in_features=500, out_features=8901, bias=True)\n",
       "  (attn): Attn()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reconstruct models\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "\n",
    "encoder = EncoderRNN(hidden_size=hidden_size, \n",
    "                     embedding=nn.Embedding(num_embeddings=voc.num_words, embedding_dim=hidden_size),\n",
    "                     n_layers=encoder_n_layers, \n",
    "                     dropout=dropout)\n",
    "\n",
    "decoder = LuongAttnDecoderRNN(attn_model='dot', \n",
    "                              embedding=nn.Embedding(num_embeddings=voc.num_words, embedding_dim=hidden_size), \n",
    "                              hidden_size=hidden_size, \n",
    "                              output_size=voc.num_words, \n",
    "                              n_layers=decoder_n_layers, \n",
    "                              dropout=dropout)\n",
    "\n",
    "# Load state into encoder and decoder\n",
    "encoder.load_state_dict(encoder_state_dict)\n",
    "decoder.load_state_dict(decoder_state_dict)\n",
    "\n",
    "# Set layers to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss & Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss, label='Train loss')\n",
    "plt.plot(val_loss, label='Validation loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_perplexity, label='Train perplexity')\n",
    "plt.plot(val_perplexity, label='Validation perplexity')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input utterances generated by chat-GPT\n",
    "input_utts = [\n",
    "    \"Why do I always get stuck in the middle of everyone's problems ?\",\n",
    "    \"Imagine if we could solve disputes with a dance-off instead of arguments .\",\n",
    "    \"Do you think a penguin could be a good pet in the city ?\",\n",
    "    \"I accidentally sent a love confession to the group chat , help !\",\n",
    "    \"What's the weirdest thing you've ever done to impress a crush ?\",\n",
    "    \"Have you ever walked into a room and forgotten why you're there ?\",\n",
    "    \"Why is it that every time I try to cook , the fire alarm goes off ?\",\n",
    "    \"I just tried talking to my crush , and I could only speak in movie quotes .\",\n",
    "    \"If you had to choose , would you rather give up coffee or pizza ?\",\n",
    "    \"Is it okay to wear socks with sandals if nobody's going to see ?\",\n",
    "    \"Why do I feel like my laundry multiplies every time I blink ?\",\n",
    "    \"Do you believe in love at first sight , or should I walk by again ?\",\n",
    "    \"What's your take on eating pizza with a fork and knife ?\",\n",
    "    \"Is talking to plants really supposed to help them grow ?\",\n",
    "    \"I dreamed I was a muffin ; what do you think it means ?\",\n",
    "    \"Why is it that I can never find my keys when I'm late ?\",\n",
    "    \"Do you think ducks have best friends ?\",\n",
    "    \"I just found out I've been using a word wrong my entire life .\",\n",
    "    \"Would you rather fight one horse-sized duck or a hundred duck-sized horses ?\",\n",
    "    \"What's the protocol for accidentally waving at someone who wasn't waving at you ?\",\n",
    "    \"Do you ever practice conversations in your head before having them ?\",\n",
    "    \"How many days in a row can you wear the same pair of jeans ?\",\n",
    "    \"Why does my phone always die at the worst possible times ?\",\n",
    "    \"Have you ever sent a text about someone to that person by accident ?\",\n",
    "    \"What's the most embarrassing song you love ?\",\n",
    "    \"Why do I feel like I need a vacation from my vacation ?\",\n",
    "    \"Do you think it's possible to be too good at thumb wrestling ?\",\n",
    "    \"What would you do if you found out you had a secret twin ?\",\n",
    "    \"Why are my awkward moments always witnessed by the most people ?\",\n",
    "    \"If you could have any superpower , but it had to be really mundane , what would it be ?\",\n",
    "    \"What's the silliest reason you've ever had a falling out with someone ?\",\n",
    "    \"Have you ever tried to bake something and it turned into a disaster ?\",\n",
    "    \"Is double-dipping really that bad ?\",\n",
    "    \"What's the strangest coincidence you've ever experienced ?\",\n",
    "    \"Have you ever laughed so hard , no sound came out , and you just sat there clapping like a seal ?\",\n",
    "    \"Why is it that when you're trying not to laugh , everything becomes ten times funnier ?\",\n",
    "    \"Do you think if we didn't have thumbs , we'd still be the dominant species ?\",\n",
    "    \"What's the best way to subtly escape a boring conversation ?\",\n",
    "    \"Have you ever had a dream where you showed up to work in your pajamas ?\",\n",
    "    \"Why do I always crave snacks right after I decide to start eating healthier ?\",\n",
    "    \"Do you ever wonder what your pet names you in their head ?\",\n",
    "    \"What's the worst haircut you've ever had ?\",\n",
    "    \"Have you ever accidentally memorized a song you hate ?\",\n",
    "    \"Why is deciding what to have for dinner the hardest decision of the day ?\",\n",
    "    \"Is it really a road trip if you don't sing along to the radio at the top of your lungs ?\",\n",
    "    \"Have you ever tried to make a recipe you saw in a cartoon ?\",\n",
    "    \"What's the funniest thing you've ever seen a stranger do ?\",\n",
    "    \"Do you think time travel will ever be possible , and if so , what time would you visit ?\",\n",
    "    \"Why is it that every time I try to be cool , I end up doing something awkward ?\",\n",
    "    \"If animals could talk , which species do you think would be the most annoying ?\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy Search Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: how are you ?\n",
      "Output: i yeah i i i i i i i .\n"
     ]
    }
   ],
   "source": [
    "# Create searcher instance\n",
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "\n",
    "# Input sentence\n",
    "input_sentence = \"how are you ?\"\n",
    "\n",
    "# Evaluate sentence\n",
    "output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "output_sentence = ' '.join(output_words)\n",
    "\n",
    "print('Input:', input_sentence)\n",
    "print('Output:', output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"why do i always get stuck in the middle of everyone's problems ?\",\n",
       " 'do you think a penguin could be a good pet in the city ?',\n",
       " \"what's the weirdest thing you've ever done to impress a crush ?\",\n",
       " \"have you ever walked into a room and forgotten why you're there ?\",\n",
       " \"what's your take on eating pizza with a fork and knife ?\",\n",
       " 'is talking to plants really supposed to help them grow ?',\n",
       " 'i dreamed i was a muffin what do you think it means ?',\n",
       " \"why is it that i can never find my keys when i'm late ?\",\n",
       " 'do you think ducks have best friends ?',\n",
       " \"i just found out i've been using a word wrong my entire life .\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_utts_normalized = [normalizeString(utt) for utt in input_utts]\n",
    "input_utts_filtered = [input_utt for input_utt in input_utts_normalized if all(word in voc.word2index.keys() for word in input_utt.split())]\n",
    "input_utts_filtered[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for input utterance 1 / 25...\n",
      "Generating responses for input utterance 2 / 25...\n",
      "Generating responses for input utterance 3 / 25...\n",
      "Generating responses for input utterance 4 / 25...\n",
      "Generating responses for input utterance 5 / 25...\n",
      "Generating responses for input utterance 6 / 25...\n",
      "Generating responses for input utterance 7 / 25...\n",
      "Generating responses for input utterance 8 / 25...\n",
      "Generating responses for input utterance 9 / 25...\n",
      "Generating responses for input utterance 10 / 25...\n",
      "Generating responses for input utterance 11 / 25...\n",
      "Generating responses for input utterance 12 / 25...\n",
      "Generating responses for input utterance 13 / 25...\n",
      "Generating responses for input utterance 14 / 25...\n",
      "Generating responses for input utterance 15 / 25...\n",
      "Generating responses for input utterance 16 / 25...\n",
      "Generating responses for input utterance 17 / 25...\n",
      "Generating responses for input utterance 18 / 25...\n",
      "Generating responses for input utterance 19 / 25...\n",
      "Generating responses for input utterance 20 / 25...\n",
      "Generating responses for input utterance 21 / 25...\n",
      "Generating responses for input utterance 22 / 25...\n",
      "Generating responses for input utterance 23 / 25...\n",
      "Generating responses for input utterance 24 / 25...\n",
      "Generating responses for input utterance 25 / 25...\n"
     ]
    }
   ],
   "source": [
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "attempts = 50\n",
    "outputs = [[] for _ in range(len(input_utts_filtered))]\n",
    "\n",
    "for idx, input_utt in enumerate(input_utts_filtered):\n",
    "    print(f\"Generating responses for input utterance {idx + 1} / {len(input_utts_filtered)}...\")\n",
    "    for _ in range(attempts):\n",
    "        output_words = evaluate(encoder, decoder, searcher, voc, input_utt)\n",
    "        output_utt = ' '.join(output_words)\n",
    "        outputs[idx].append(output_utt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct-1: 0.0060\n",
      "Distinct-2: 0.0082\n"
     ]
    }
   ],
   "source": [
    "distinct_1 = [calculate_distinct_n_grams(outputs[i], n=1) for i in range(len(input_utts_filtered))]\n",
    "distinct_2 = [calculate_distinct_n_grams(outputs[i], n=2) for i in range(len(input_utts_filtered))]\n",
    "\n",
    "print(f\"Distinct-1: {np.mean(distinct_1):.4f}\")\n",
    "print(f\"Distinct-2: {np.mean(distinct_2):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beam Search Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create searcher instance\n",
    "beam_width = 10\n",
    "searcher = BeamSearchDecoder(encoder, decoder, beam_width)\n",
    "\n",
    "# Input sentence\n",
    "input_sentence = \"how are you ?\"\n",
    "\n",
    "# Evaluate sentence\n",
    "output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "output_sentence = ' '.join(output_words)\n",
    "\n",
    "print('Input:', input_sentence)\n",
    "print('Output:', output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_utts_normalized = [normalizeString(utt) for utt in input_utts]\n",
    "input_utts_filtered = [input_utt for input_utt in input_utts_normalized if all(word in voc.word2index.keys() for word in input_utt.split())]\n",
    "input_utts_filtered[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "attempts = 50\n",
    "outputs = [[] for _ in range(len(input_utts_filtered))]\n",
    "\n",
    "for idx, input_utt in enumerate(input_utts_filtered):\n",
    "    print(f\"Generating responses for input utterance {idx + 1} / {len(input_utts_filtered)}...\")\n",
    "    for _ in range(attempts):\n",
    "        output_words = evaluate(encoder, decoder, searcher, voc, input_utt)\n",
    "        output_utt = ' '.join(output_words)\n",
    "        outputs[idx].append(output_utt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_1 = [calculate_distinct_n_grams(outputs[i], n=1) for i in range(len(input_utts_filtered))]\n",
    "distinct_2 = [calculate_distinct_n_grams(outputs[i], n=2) for i in range(len(input_utts_filtered))]\n",
    "\n",
    "print(f\"Distinct-1: {np.mean(distinct_1):.4f}\")\n",
    "print(f\"Distinct-2: {np.mean(distinct_2):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
